{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('./bap-imgap-212022/train.csv')\n",
    "print(df_training.head(), '\\n')\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('./bap-imgap-212022/test.csv')\n",
    "print(df_test.head())\n",
    "\n",
    "\n",
    "def get_data_from_mat(train_file, test_file):\n",
    "    train_mat = scipy.io.loadmat(train_file) \n",
    "    test_mat = scipy.io.loadmat(test_file) \n",
    "\n",
    "    train_np = np.array(train_mat['train_data']).transpose(2, 0, 1)\n",
    "    test_np = np.array(test_mat['test_data']).transpose(2, 0, 1)\n",
    "\n",
    "    print(train_np.shape)\n",
    "    print(test_np.shape)\n",
    "\n",
    "    return train_np, test_np\n",
    "\n",
    "train_data, test_data = get_data_from_mat('./bap-imgap-212022/train_data.mat','./bap-imgap-212022/test_data.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brain Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = pd.read_csv('./bap-imgap-212022/regions.csv')\n",
    "regions = regions.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = []\n",
    "connecitvity = []\n",
    "done = False\n",
    "\n",
    "for t in train_data:\n",
    "    aux = []\n",
    "    for i in range(len(t)):\n",
    "        for j in range(len(t[i])):\n",
    "            if i > j:\n",
    "                aux.append(t[i][j])\n",
    "                if not done:\n",
    "                    connecitvity.append(str(regions.loc[regions.index[i]]['region']) + '--' + str(regions.loc[regions.index[j]]['region']))\n",
    "    \n",
    "    done = True\n",
    "\n",
    "    original_train_data.append(aux)\n",
    "\n",
    "original_train_data = np.array(original_train_data)\n",
    "original_train_data = pd.DataFrame(original_train_data, columns = connecitvity)\n",
    "\n",
    "df_training = pd.concat([df_training, original_train_data], axis = 1)\n",
    "\n",
    "df_training = df_training.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURE_METRICS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_dic = {}\n",
    "vars = df_training.var()\n",
    "\n",
    "for i in range(len(vars)):\n",
    "    vars_dic[df_training.columns[i]] = vars[i]\n",
    "\n",
    "top_vars = sorted(vars_dic.items(), key = lambda x: x[1], reverse = True)[0:NUM_FEATURE_METRICS]\n",
    "print(top_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skews_dic = {}\n",
    "skews = df_training.skew()\n",
    "\n",
    "for i in range(len(skews)):\n",
    "    skews_dic[df_training.columns[i]] = skews[i]\n",
    "\n",
    "\n",
    "top_skews = []\n",
    "\n",
    "for e in sorted(skews_dic.items(), key = lambda x: abs(x[1]), reverse = False):\n",
    "    if e[1] != 0.0:\n",
    "        top_skews.append(e)\n",
    "\n",
    "\n",
    "top_skews = top_skews[0:NUM_FEATURE_METRICS]\n",
    "print(top_skews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurts_dic = {}\n",
    "kurts = df_training.kurt()\n",
    "\n",
    "for i in range(len(kurts)):\n",
    "    kurts_dic[df_training.columns[i]] = kurts[i]\n",
    "\n",
    "\n",
    "top_kurts = []\n",
    "\n",
    "for e in sorted(kurts_dic.items(), key = lambda x: abs(x[1]), reverse = False):\n",
    "    if e[1] != 0.0:\n",
    "        top_kurts.append(e)\n",
    "\n",
    "\n",
    "top_kurts = top_kurts[0:NUM_FEATURE_METRICS]\n",
    "print(top_kurts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = df_training.corr()\n",
    "corrs = corrs['age'][1:]\n",
    "\n",
    "corrs_dic = {}\n",
    "\n",
    "for i in range(len(corrs)):\n",
    "    corrs_dic[df_training.columns[i]] = corrs[i] if not math.isnan(corrs[i]) else 0.0\n",
    "\n",
    "top_corrs = sorted(corrs_dic.items(), key = lambda x: abs(x[1]), reverse = True)[0:NUM_FEATURE_METRICS]\n",
    "print(top_corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_training.drop(['age'], axis = 1)\n",
    "y = df_training['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countDup(data, elem):\n",
    "    i = 0\n",
    "\n",
    "    for e in data:\n",
    "        if e == elem:\n",
    "            i += 1\n",
    "\n",
    "    return i\n",
    "\n",
    "\n",
    "def validationSplit(data):\n",
    "    val = []\n",
    "    blacklist = []\n",
    "\n",
    "    for e in range(len(data)):\n",
    "        if data[e] not in blacklist:\n",
    "            if countDup(data, data[e]) > 5:\n",
    "                index = takePerc(data, 0.3, data[e])\n",
    "\n",
    "                for i in index:\n",
    "                    val.append(i)\n",
    "\n",
    "            elif countDup(data, data[e]) > 1 and countDup(data, data[e]) <= 5:\n",
    "                val.append(e)\n",
    "            \n",
    "            blacklist.append(data[e])\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "def takePerc(data, perc, elem):\n",
    "    threshold = int(countDup(data, elem) * perc)\n",
    "    i = 0\n",
    "    index = []\n",
    "\n",
    "    for e in range(len(data)):\n",
    "        if i < threshold:\n",
    "            if data[e] == elem:\n",
    "                index.append(e)\n",
    "                i += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "def split(x, y, index):\n",
    "\n",
    "    x_train = x\n",
    "    y_train = y\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "\n",
    "    for i in index:\n",
    "        x_val.append(x.loc[x.index[i]])\n",
    "        y_val.append(y[i])\n",
    "        x_train = x_train.drop([i], axis = 0)\n",
    "        y_train = y_train.drop([i], axis = 0)\n",
    "\n",
    "    return x_train, np.array(x_val), y_train, np.array(y_val)\n",
    "\n",
    "index = np.array(validationSplit(y))\n",
    "x_train, x_val, y_train, y_val = split(x, y, index)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x = 'age', data = pd.DataFrame(y, columns = ['age']), palette = 'rainbow')\n",
    "plt.show()\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x = 'age', data = pd.DataFrame(y_train, columns = ['age']), palette = 'rainbow')\n",
    "plt.show()\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x = 'age', data = pd.DataFrame(y_val, columns = ['age']), palette = 'rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 1\n",
    "\n",
    "def prepare_callbacks(file):\n",
    "    checkpoint = ModelCheckpoint(filepath = file, monitor = 'val_loss', \n",
    "                                 verbose = 1, save_weights_only = True, save_best_only = True)\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor = 'val_loss', min_delta = 0.00001, patience = 50, verbose = 1)\n",
    "\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 5, min_lr = 0.000000001, verbose = 1)\n",
    "\n",
    "    return [checkpoint, earlyStopper, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(output, input):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape = (input,)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(output, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate = 0.001), loss = 'mae')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "test = createModel(1, x_train.shape[1])\n",
    "print(test.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "def runningPipeline(path):\n",
    "    for i in range(5):\n",
    "        model = createModel(1, x_train.shape[1])\n",
    "\n",
    "        _ = model.fit(x = x_train, y = y_train, epochs = 1000, batch_size = BATCHSIZE, \n",
    "                      validation_data = (x_val, y_val), \n",
    "                      callbacks = prepare_callbacks(path + f'/model{i}/cp.ckpt'))\n",
    "\n",
    "if TRAIN:\n",
    "    runningPipeline('./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATE = True\n",
    "\n",
    "def evaluatePipeline(path):\n",
    "    for i in range(5):\n",
    "        model = createModel(1, x_train.shape[1])\n",
    "\n",
    "        model.load_weights(path + f'/model{i}/cp.ckpt')\n",
    "\n",
    "        print(model.evaluate(x_val, y_val, batch_size = BATCHSIZE, verbose = 2))\n",
    "    \n",
    "if EVALUATE:\n",
    "    evaluatePipeline('./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = 2\n",
    "\n",
    "model = createModel(1, x_train.shape[1])\n",
    "model.load_weights(f'./models/model{bestModel}/cp.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_IMPORTANCE = False\n",
    "\n",
    "if FEATURE_IMPORTANCE:\n",
    "    r = permutation_importance(model, x_val, y_val, n_repeats = 5, random_state = 0, scoring = ['neg_mean_absolute_error'])\n",
    "    r = r['neg_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 10\n",
    "count = 0\n",
    "dic = {}\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if count < NUM_FEATURES:\n",
    "        if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            dic[x.columns[i]] = (r.importances_mean[i], r.importances_std[i])\n",
    "            count += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Subjects to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.around(model.predict(x), 0)\n",
    "\n",
    "NUM_ROWS = 10\n",
    "dic = {}\n",
    "\n",
    "for p in range(len(predictions)):\n",
    "    error = abs(predictions[p] - y[p])\n",
    "    dic[p + 1] = error[0]\n",
    "\n",
    "dic = {k: v for k, v in sorted(dic.items(), key = lambda item: item[1])}\n",
    "\n",
    "\n",
    "top = [(k, v) for k, v in dic.items()][-NUM_ROWS:]\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['id'], axis = 1)\n",
    "\n",
    "new_test_data = []\n",
    "PREDICT = False\n",
    "\n",
    "for t in test_data:\n",
    "    aux = []\n",
    "    for i in range(len(t)):\n",
    "        for j in range(len(t[i])):\n",
    "            if i > j:\n",
    "                aux.append(t[i][j])\n",
    "\n",
    "    new_test_data.append(aux)\n",
    "\n",
    "new_test_data = np.array(new_test_data)\n",
    "new_test_data = pd.DataFrame(new_test_data)\n",
    "\n",
    "test_data = pd.concat([df_test, new_test_data], axis = 1)\n",
    "\n",
    "if PREDICT:\n",
    "    predictions = model.predict(test_data)\n",
    "    predictions = np.around(predictions, 0)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = False\n",
    "\n",
    "if WRITE:\n",
    "    f = open('submission.csv', 'w+')\n",
    "\n",
    "    f.write('id,age\\n')\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        f.write(str(i + 1) + ',' + str(int(predictions[i][0])) + '\\n')\n",
    "\n",
    "    f.flush()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16a84799b4554b55119e03db3af09132791ba03da067a3440fe10ca44b449a97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
