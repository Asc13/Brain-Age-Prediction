{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import cv2\n",
    "\n",
    "from cmath import exp\n",
    "from shutil import rmtree, move\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join, isdir\n",
    "from scipy import signal\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('./bap-imgap-212022/train.csv')\n",
    "print(df_training.head(), '\\n')\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('./bap-imgap-212022/test.csv')\n",
    "print(df_test.head())\n",
    "\n",
    "\n",
    "def get_data_from_mat(train_file, test_file):\n",
    "    train_mat = scipy.io.loadmat(train_file) \n",
    "    test_mat = scipy.io.loadmat(test_file) \n",
    "\n",
    "    train_np = np.array(train_mat['train_data']).transpose(2, 0, 1)\n",
    "    test_np = np.array(test_mat['test_data']).transpose(2, 0, 1)\n",
    "\n",
    "    print(train_np.shape)\n",
    "    print(test_np.shape)\n",
    "\n",
    "    return train_np, test_np\n",
    "\n",
    "train_data, test_data = get_data_from_mat('./bap-imgap-212022/train_data.mat','./bap-imgap-212022/test_data.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create New Augmentation Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_data)\n",
    "ages = []\n",
    "\n",
    "path = './train_data/Original/'\n",
    "\n",
    "if isdir(path):\n",
    "    rmtree(path, ignore_errors = False, onerror = None)\n",
    "\n",
    "mkdir(path)\n",
    "\n",
    "for i in range(N):\n",
    "    age = df_training.loc[df_training.index[i], 'age']\n",
    "\n",
    "    if age not in ages:\n",
    "        ages.append(age)\n",
    "\n",
    "    if age:\n",
    "        new_path = path + str(age) + '/'\n",
    "\n",
    "        if not isdir(new_path):\n",
    "            mkdir(new_path)\n",
    "\n",
    "        cv2.imwrite(new_path + \n",
    "                    format(i, '05d') + '_' +\n",
    "                    format(0, '05d') + '.png', train_data[i] * 255.0)\n",
    "\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAugTypes = ['Sharpness1', 'Sharpness2', 'GaussianBlur', 'EdgeDet1', 'EdgeDet2', 'EdgeDet3', 'EdgeDet4', 'EdgeDet5', 'EdgeDet6', \n",
    "'MotionBlur1', 'MotionBlur2', 'Box', 'Emboss1', 'Emboss2', 'FilterWithoutConv1', 'FilterWithoutConv2', 'FilterWithoutConv3', \n",
    "'FilterWithoutConv4', 'Deconvolution', 'Fourier1', 'Fourier2', 'HistEqualization1', 'HistEqualization2', 'GaussDiff1', \n",
    "'GaussDiff2', 'GaussDiff3', 'GaussDiff4', 'GaussDiff5', 'Harris', 'ShiTomasi', 'SIFT', 'ColorMap1', 'ColorMap2', 'ColorMap3',\n",
    "'ColorMap4', 'ColorMap5', 'ColorMap6', 'ColorMap7', 'ColorMap8', 'ColorMap9', 'ColorMap10', 'ColorMap11', 'ColorMap12', 'ColorMap13', \n",
    "'ColorMap14', 'ColorMap15', 'ColorMap16', 'ColorMap17', 'ColorMap18', 'ColorMap19', 'ColorMap20', 'ColorMap21', 'ColorMap22', \n",
    "'Dilation', 'Closing', 'Thresholding', 'AdaptiveThresholding', 'Binarization']\n",
    "\n",
    "path = './train_data'\n",
    "original = path + '/Original/'\n",
    "\n",
    "def createTypeFolders():\n",
    "    for type in DataAugTypes:\n",
    "        newpath = path + '/' + type\n",
    "\n",
    "        if isdir(newpath):\n",
    "            rmtree(newpath, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(newpath)\n",
    "\n",
    "createTypeFolders()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Appliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyKernel(kernel, path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            res = cv2.filter2D(src = img, ddepth = -1, kernel = kernel)\n",
    "            \n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyDoubleKernel(kernel1, kernel2, path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            resH = cv2.filter2D(src = img, ddepth = -1, kernel = kernel1)\n",
    "            resV = cv2.filter2D(src = img, ddepth = -1, kernel = kernel2)\n",
    "\n",
    "            res = resH + resV\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def find_zero_crossings(res):\n",
    "    res = np.asarray(res)\n",
    "    res2 = [[np.abs(res[i][j] - res[i + 1][j])\n",
    "                if (res[i][j] <= 0 and res[i + 1][j] > 0) or (res[i][j] >= 0 and res[i + 1][j] < 0)  else 0\n",
    "                for j in range(1, res.shape[1] -1)] for i in range(1, res.shape[0] -1)]\n",
    "\n",
    "    res3 =  [[np.abs(res[i][j]-res[i][j+1])\n",
    "                if (res[i][j] <= 0 and res[i][j + 1] > 0) or (res[i][j] >= 0 and res[i][j + 1] < 0)  else 0\n",
    "                for j in range(1, res.shape[1] - 1)] for i in range(1, res.shape[0] - 1)]\n",
    "\n",
    "    res4 = np.asarray(res2) + np.asarray(res3)   \n",
    "  \n",
    "    return res4\n",
    "\n",
    "\n",
    "def applyLaplacianAlternative(kernel1, kernel2, path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            resX = signal.convolve2d(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), kernel1)\n",
    "            resY = signal.convolve2d(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), kernel2)\n",
    "\n",
    "            resT = resX + resY\n",
    "            \n",
    "            resZC = find_zero_crossings(resT)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, resZC)\n",
    "\n",
    "\n",
    "\n",
    "def applyCanny(path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            res = cv2.Canny(img, 70, 90)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyFilterWithoutConv(path, original, filter):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            \n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if filter == 0:\n",
    "                res = cv2.medianBlur(img, 3)\n",
    "\n",
    "            elif filter == 1:\n",
    "                res = cv2.GaussianBlur(img, (7, 7), -1)\n",
    "\n",
    "            elif filter == 2:\n",
    "                res = cv2.bilateralFilter(img, 3, 90, 90)\n",
    "            \n",
    "            elif filter == 3:\n",
    "                gaussian = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "                unsharp_mask = cv2.addWeighted(img, 1.0, gaussian, -1.0, 0)\n",
    "                res = cv2.medianBlur(unsharp_mask, 3)\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "ANGLE = np.deg2rad(135)\n",
    "D = 22\n",
    "noise = 10 ** (-0.1 * 25)\n",
    "\n",
    "\n",
    "def blur_edge(img, d = 31):\n",
    "    h, w  = img.shape[:2]\n",
    "    \n",
    "    img_pad = cv2.copyMakeBorder(img, d, d, d, d, cv2.BORDER_WRAP)\n",
    "    img_blur = cv2.GaussianBlur(img_pad, (2 * d + 1, 2 * d + 1), -1)[d:-d, d:-d]\n",
    "    \n",
    "    y, x = np.indices((h, w))\n",
    "    dist = np.dstack([x, w - x - 1, y, h - y - 1]).min(-1)\n",
    "    w = np.minimum(np.float32(dist) / d, 1.0)\n",
    "    \n",
    "    return img * w + img_blur * (1 - w)\n",
    "\n",
    "\n",
    "def motion_kernel(angle, d, sz = 1):\n",
    "    kern = np.ones((1, d), np.float32)\n",
    "    c, s = np.cos(angle), np.sin(angle)\n",
    "    \n",
    "    A = np.float32([[c, -s, 0], [s, c, 0]])\n",
    "    sz2 = sz // 2\n",
    "    \n",
    "    A[:, 2] = (sz2, sz2) - np.dot(A[:,:2], ((d - 1) * 0.5, 0))\n",
    "    kern = cv2.warpAffine(kern, A, (sz, sz), flags = cv2.INTER_CUBIC)\n",
    "    \n",
    "    return kern\n",
    "\n",
    "\n",
    "def applyDeconvolution(path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "            img = np.float32(img) / 255.0\n",
    "\n",
    "            img_be = blur_edge(img)\n",
    "\n",
    "            img_aux = img_be\n",
    "            dft = cv2.dft(img_aux, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "            dft_shift = np.fft.fftshift(dft)\n",
    "            \n",
    "            psf = motion_kernel(ANGLE, D)\n",
    "            \n",
    "            psf /= psf.sum()\n",
    "            psf_pad = np.zeros_like(img)\n",
    "            kh, kw = psf.shape\n",
    "            psf_pad[:kh, :kw] = psf\n",
    "            PSF = cv2.dft(psf_pad, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "\n",
    "            PSF2 = (PSF ** 2).sum(-1)\n",
    "            iPSF = PSF.conjugate() / (PSF2 + noise)[..., np.newaxis]\n",
    "            RES = cv2.mulSpectrums(dft, iPSF, 0)\n",
    "            res = cv2.idft(RES, flags = cv2.DFT_SCALE | cv2.DFT_REAL_OUTPUT)\n",
    "            \n",
    "            res = np.float32(res) * 255\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def gauss(std, x, y):\n",
    "    d = x ** 2 + y ** 2\n",
    "    g =  exp(-d / (2 * std ** 2))\n",
    "\n",
    "    return g\n",
    "\n",
    "    \n",
    "def gaussianLP(std, img_shape):\n",
    "    return np.asarray([[gauss(std, x-img_shape[0]/2,y-img_shape[1]/2)  for y in range(img_shape[1])] for x in range(img_shape[0])])\n",
    "\n",
    "\n",
    "def gaussianHP(std, img_shape):\n",
    "    return np.asarray([[1 - gauss(std, x - img_shape[0] / 2, y - img_shape[1] / 2)  for y in range(img_shape[1])] for x in range(img_shape[0])])        \n",
    "\n",
    "\n",
    "filter_strength = 8\n",
    "\n",
    "def applyFourier(path, original, filter):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            image_grey_fourier = np.fft.fft2(img)\n",
    "\n",
    "            if filter == 0:\n",
    "                GaussianLP = gaussianLP(filter_strength, img.shape)\n",
    "                filtered = np.fft.fftshift(image_grey_fourier) * GaussianLP\n",
    "                LowPass = np.fft.ifftshift(filtered)\n",
    "                res = np.fft.ifft2(LowPass)\n",
    "\n",
    "            elif filter == 1:\n",
    "                GaussianHP = gaussianHP(filter_strength, img.shape)\n",
    "                filtered = np.fft.fftshift(image_grey_fourier) * GaussianHP\n",
    "                HighPass = np.fft.ifftshift(filtered)\n",
    "                res = np.fft.ifft2(HighPass)\n",
    "\n",
    "            else: \n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res.real)\n",
    "\n",
    "\n",
    "\n",
    "def applyHistogramEqualization(path, original, filter):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if filter == 0:\n",
    "                res = cv2.equalizeHist(img)\n",
    "\n",
    "            elif filter == 1:\n",
    "                clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (8, 8))\n",
    "                res = clahe.apply(img)\n",
    "\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_kernel(dimension):\n",
    "    x = cv2.getGaussianKernel(dimension, -1)\n",
    "    kernel = x.dot(x.T)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def applyGaussDiff(path, original, size):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            kernel1 = gaussian_kernel(size - 2)\n",
    "            kernel2 = gaussian_kernel(size)\n",
    "\n",
    "            res1 = cv2.filter2D(img, -1, kernel1)\n",
    "            res2 = cv2.filter2D(img, -1, kernel2)\n",
    "\n",
    "            res = res2 - res1\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyHarrisCorners(path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "            dst = cv2.cornerHarris(img, 2, 11, 0.04)\n",
    "            dst = cv2.dilate(dst, None)\n",
    "\n",
    "            res = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            res[np.abs(dst) > 0.04 * dst.max()] = [0, 255, 0]\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyShiTomasi(path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            corners = cv2.goodFeaturesToTrack(img, 2500, 0.01, 10)\n",
    "\n",
    "            corners = np.int0(corners)\n",
    "\n",
    "            res = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            for i in corners:\n",
    "                x, y = i.ravel()\n",
    "                cv2.circle(res, (x, y), 1, 255, -1)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applySIFT(path, original):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            sift = cv2.SIFT_create()\n",
    "            kp = sift.detect(img, None)\n",
    "\n",
    "            res = cv2.drawKeypoints(img, kp, img, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyColorMap(path, original, map):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            res = cv2.applyColorMap(img, map)\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyTransform(path, original, flag):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if flag == 0:\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                res = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            elif flag == 1:\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                res = cv2.dilate(img, kernel, iterations = 1)\n",
    "\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)\n",
    "\n",
    "\n",
    "\n",
    "def applyThresholding(path, original, flag):\n",
    "    for a in ages:\n",
    "        path_dir = path + str(a) + '/'\n",
    "\n",
    "        if isdir(path_dir):\n",
    "            rmtree(path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(path_dir)\n",
    "\n",
    "        original_dir = original + str(a) + '/'\n",
    "        onlyfiles = [f for f in listdir(original_dir) if isfile(join(original_dir, f))]\n",
    "\n",
    "        for f in onlyfiles:\n",
    "            img = cv2.imread(original_dir + f, 0)\n",
    "\n",
    "            if flag == 0:\n",
    "                img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "                _, res = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "            elif flag == 1: \n",
    "                img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "                res = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5)\n",
    "\n",
    "            elif flag == 2:\n",
    "                _, res = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            else:\n",
    "                res = img\n",
    "\n",
    "            cv2.imwrite(path_dir + f, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sharpness Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = np.array([[0, -1, 0],\n",
    "                    [-1, 5,-1],\n",
    "                    [0, -1, 0]])\n",
    "\n",
    "kernel2 = np.array([[-1, -1, -1],\n",
    "                    [-1,  9, -1],\n",
    "                    [-1, -1, -1]])\n",
    "\n",
    "\n",
    "kernel1 = kernel1 / np.sum(kernel1)\n",
    "\n",
    "kernel2 = kernel2 / np.sum(kernel2)\n",
    "\n",
    "path1 = './train_data/Sharpness1/'\n",
    "path2 = './train_data/Sharpness2/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(dimension):\n",
    "    x = cv2.getGaussianKernel(dimension, -1)\n",
    "    kernel = x.dot(x.T)\n",
    "    return kernel\n",
    "\n",
    "kernel = gaussian_kernel(3)\n",
    "\n",
    "path = './train_data/GaussianBlur/'\n",
    "\n",
    "applyKernel(kernel, path, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Laplacian Approximations\n",
    "kernel1 = np.array([[-1, -1, -1],\n",
    "                    [-1, 8, -1],\n",
    "                    [-1, -1, -1]])\n",
    "\n",
    "kernel2 = np.array([[0, 1, 0],\n",
    "                    [1, -4, 1],\n",
    "                    [0, 1, 0]])\n",
    "\n",
    "\n",
    "# Prewit\n",
    "kernel3H = np.array([[-1, -1, -1],\n",
    "                     [0,  0,  0],\n",
    "                     [1,  1,  1]])\n",
    "\n",
    "kernel3V = np.array([[-1, 0, 1],\n",
    "                     [-1, 0, 1],\n",
    "                     [-1, 0, 1]])\n",
    "\n",
    "\n",
    "# Scharr\n",
    "kernel4H = np.array([[-3, -10, -3],\n",
    "                     [0,   0,  0],\n",
    "                     [3,  10,  3]])\n",
    "\n",
    "kernel4V = np.array([[-3, 0,  3],\n",
    "                     [-10, 0, 10],\n",
    "                     [-3, 0,  3]])\n",
    "\n",
    "\n",
    "# Laplacian Alternative\n",
    "kernel5X = np.array([[-1, 2, -1],\n",
    "                     [-2, 4, -2],\n",
    "                     [-1, 2, -1]])\n",
    "\n",
    "kernel5Y = np.array([[-1, -2, -1],\n",
    "                     [2,  4,  2],\n",
    "                     [-1, -2, -1]])\n",
    "\n",
    "\n",
    "path1 = './train_data/EdgeDet1/'\n",
    "path2 = './train_data/EdgeDet2/'\n",
    "path3 = './train_data/EdgeDet3/'\n",
    "path4 = './train_data/EdgeDet4/'\n",
    "path5 = './train_data/EdgeDet5/'\n",
    "path6 = './train_data/EdgeDet6/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)\n",
    "applyDoubleKernel(kernel3H, kernel3V, path3, original)\n",
    "applyDoubleKernel(kernel4H, kernel4V, path4, original)\n",
    "applyLaplacianAlternative(kernel5X, kernel5Y, path5, original)\n",
    "applyCanny(path6, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Motion Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = np.array([[0, 0, 0, 0, 0, 0, 1],\n",
    "                    [0, 0, 0, 0, 0, 1, 0],\n",
    "                    [0, 0, 0, 0, 1, 0, 0],\n",
    "                    [0, 0, 0, 1, 0, 0, 0],\n",
    "                    [0, 0, 1, 0, 0, 0, 0],\n",
    "                    [0, 1, 0, 0, 0, 0, 0],\n",
    "                    [1, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "kernel2 = np.array([[0, 0, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 1, 1, 1],\n",
    "                    [0, 0, 1, 1, 0, 0, 0],\n",
    "                    [1, 1, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "kernel1 = kernel1 / np.sum(kernel1)\n",
    "kernel2 = kernel2 / np.sum(kernel2)\n",
    "\n",
    "path1 = './train_data/MotionBlur1/'\n",
    "path2 = './train_data/MotionBlur2/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Box filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 7\n",
    "kernel = np.ones((dim, dim))\n",
    "kernel = kernel / np.sum(kernel)\n",
    "\n",
    "path = './train_data/Box/'\n",
    "\n",
    "applyKernel(kernel, path, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Emboss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = np.array([[-2, -1, 0],\n",
    "                    [-1,  1, 1],\n",
    "                    [ 0,  1, 2]])\n",
    "\n",
    "kernel2 = np.array([[0,  1, 2],\n",
    "                    [-1,  1, 1],\n",
    "                    [-2, -1, 0]])\n",
    "\n",
    "kernel1 = kernel1 / np.sum(kernel1)\n",
    "\n",
    "kernel2 = kernel2 / np.sum(kernel2)\n",
    "\n",
    "path1 = './train_data/Emboss1/'\n",
    "path2 = './train_data/Emboss2/'\n",
    "\n",
    "applyKernel(kernel1, path1, original)\n",
    "applyKernel(kernel2, path2, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Filters Without Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_data/FilterWithoutConv1/'\n",
    "path2 = './train_data/FilterWithoutConv2/'\n",
    "path3 = './train_data/FilterWithoutConv3/'\n",
    "path4 = './train_data/FilterWithoutConv4/'\n",
    "\n",
    "\n",
    "# Median Blur\n",
    "applyFilterWithoutConv(path1, original, filter = 0)\n",
    "\n",
    "# Gaussian Blur\n",
    "applyFilterWithoutConv(path2, original, filter = 1)\n",
    "\n",
    "# Bilateral Filter\n",
    "applyFilterWithoutConv(path3, original, filter = 2)\n",
    "\n",
    "# Unsharp Mask\n",
    "applyFilterWithoutConv(path4, original, filter = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './train_data/Deconvolution/'\n",
    "\n",
    "applyDeconvolution(path, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_data/Fourier1/'\n",
    "path2 = './train_data/Fourier2/'\n",
    "\n",
    "applyFourier(path1, original, 0)\n",
    "applyFourier(path2, original, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_data/HistEqualization1/'\n",
    "path2 = './train_data/HistEqualization2/'\n",
    "\n",
    "# Normal Equalization\n",
    "applyHistogramEqualization(path1, original, 0)\n",
    "\n",
    "# CLAHE\n",
    "applyHistogramEqualization(path2, original, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Difference of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_data/GaussDiff1/'\n",
    "path2 = './train_data/GaussDiff2/'\n",
    "path3 = './train_data/GaussDiff3/'\n",
    "path4 = './train_data/GaussDiff4/'\n",
    "path5 = './train_data/GaussDiff5/'\n",
    "\n",
    "applyGaussDiff(path1, original, 3)\n",
    "applyGaussDiff(path2, original, 5)\n",
    "applyGaussDiff(path3, original, 7)\n",
    "applyGaussDiff(path4, original, 9)\n",
    "applyGaussDiff(path5, original, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Feature Detection Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_data/Harris/'\n",
    "path2 = './train_data/ShiTomasi/'\n",
    "path3 = './train_data/SIFT/'\n",
    "\n",
    "# Harris Corners\n",
    "applyHarrisCorners(path1, original)\n",
    "\n",
    "# Shi-Tomasi\n",
    "applyShiTomasi(path2, original)\n",
    "\n",
    "# SIFT\n",
    "applySIFT(path3, original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Color Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 22):\n",
    "    path = f'./train_data/ColorMap{i + 1}/'\n",
    "    applyColorMap(path, original, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Closing and Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_data/Closing/'\n",
    "path2 = './train_data/Dilation/'\n",
    "\n",
    "applyTransform(path1, original, 0)\n",
    "applyTransform(path2, original, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Thresholding, Adaptive Thresholding, And Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './train_data/Thresholding/'\n",
    "path2 = './train_data/AdaptiveThresholding/'\n",
    "path3 = './train_data/Binarization/'\n",
    "\n",
    "applyThresholding(path1, original, 0)\n",
    "applyThresholding(path2, original, 1)\n",
    "applyThresholding(path3, original, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createValSet(path):\n",
    "    subfolders = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "    \n",
    "    for sf in subfolders:\n",
    "        new_path = re.sub(r'train_data', r'val_data', sf)\n",
    "\n",
    "        if isdir(new_path):\n",
    "            rmtree(new_path, ignore_errors = False, onerror = None)\n",
    "\n",
    "        mkdir(new_path)\n",
    "\n",
    "        for a in ages:\n",
    "            path_dir = sf + '/' + str(a) + '/'\n",
    "            new_path_dir = new_path + '/' + str(a) + '/'\n",
    "\n",
    "            onlyfiles = [f for f in listdir(path_dir) if isfile(join(path_dir, f))]\n",
    "            \n",
    "            length = len(onlyfiles)\n",
    "\n",
    "            if length == 1:\n",
    "                train_length = 1\n",
    "                val_length = 0\n",
    "            \n",
    "            elif length > 1 and length < 5:\n",
    "                train_length = length - 1\n",
    "                val_length = 1  \n",
    "\n",
    "            else:\n",
    "                train_length = int(length * 0.8)\n",
    "                val_length = length - train_length\n",
    "\n",
    "            valfiles = np.random.choice(onlyfiles, size = val_length, replace = False)\n",
    "\n",
    "            if isdir(new_path_dir):\n",
    "                rmtree(new_path_dir, ignore_errors = False, onerror = None)\n",
    "\n",
    "            mkdir(new_path_dir)\n",
    "\n",
    "            for v in valfiles:\n",
    "                move(path_dir + v, new_path_dir + v)\n",
    "\n",
    "\n",
    "createValSet('./train_data')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16a84799b4554b55119e03db3af09132791ba03da067a3440fe10ca44b449a97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
