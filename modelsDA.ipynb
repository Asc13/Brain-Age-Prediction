{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "def show_history(history):\n",
    "\tprint(history.history.keys())\n",
    "\n",
    "\t# Summarize history for loss\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title('model loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc = 'upper right')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "\tparts = tf.strings.split(file_path, os.path.sep)\n",
    "\tparts = parts[-2]\n",
    "\n",
    "\treturn tf.strings.to_number(parts, tf.int64)\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "\timg = tf.image.decode_png(img, channels = 1)\n",
    "\timg = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "\treturn tf.image.resize(img, [90, 90])\n",
    "\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "\tlabel = get_label(file_path)\n",
    "\timg = tf.io.read_file(file_path)\n",
    "\timg = decode_img(img)\n",
    "\n",
    "\treturn img, label\n",
    "\n",
    "\n",
    "def get_bytes(file_path):\n",
    "\timg = tf.io.read_file(file_path)\n",
    "\timg = decode_img(img)\n",
    "\t\n",
    "\treturn img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def createDataset(path):\n",
    "    dataset = tf.data.Dataset.list_files(path + '/*/*.png')\n",
    "    dataset = dataset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "    return dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(dataset, dataset_length):\n",
    "    \n",
    "    # Colocar o dataset na cache\n",
    "    dataset = dataset.cache()\n",
    "\n",
    "    # Baralhar as imagens, para previnir treinos de classes individuais\n",
    "    dataset = dataset.shuffle(buffer_size = dataset_length)\n",
    "\n",
    "    # Criar as batches\n",
    "    dataset = dataset.batch(batch_size = BATCH_SIZE)\n",
    "\n",
    "    # Prefetch dos dados\n",
    "    dataset = dataset.prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "    # Repetir o dataset, para n√£o acabar\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    return dataset, dataset_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_callbacks(file_path):\n",
    "    checkpointer = ModelCheckpoint(filepath = file_path, monitor = 'val_loss', verbose = 1, save_weights_only = True, save_best_only = True)\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor = 'val_loss', min_delta = 0.0001, patience = 50, verbose = 1)\n",
    "\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 8, min_lr = 0.000000001, verbose = 1)\n",
    "\n",
    "    return [checkpointer, earlyStopper, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(output, input):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape = (input, input, 1)))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(output, activation = 'linear'))\n",
    "    \n",
    "    model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'mae')\n",
    "    \n",
    "    return model\n",
    "\n",
    "test = createModel(1, 90)\n",
    "print(test.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 5\n",
    "TRAIN = False\n",
    "\n",
    "def runningPipeline(path):\n",
    "    dataset = createDataset(path)\n",
    "    dataset_length = tf.data.experimental.cardinality(dataset).numpy()\n",
    "\n",
    "    valset = createDataset(re.sub(r'train_data', r'val_data', path))\n",
    "    valset_length = tf.data.experimental.cardinality(valset).numpy()\n",
    "\n",
    "    dataset, dataset_length = prepareDataset(dataset, dataset_length)\n",
    "    valset, _ = prepareDataset(valset, valset_length)\n",
    "\n",
    "    for i in range(NUM_MODELS):\n",
    "        model = createModel(1, 90)\n",
    "        \n",
    "        _ = model.fit(dataset, epochs = 500, steps_per_epoch = dataset_length / BATCH_SIZE,  \n",
    "                      validation_data = valset, validation_steps = valset_length / BATCH_SIZE,\n",
    "                      callbacks = prepare_callbacks(re.sub('train_data', 'modelsAug', path) + f'/model{i}/cp.ckpt'))\n",
    "\n",
    "\n",
    "subfolders = [f.path for f in os.scandir('./train_data/') if f.is_dir()]\n",
    "\n",
    "if TRAIN:\n",
    "    for sf in subfolders:\n",
    "        runningPipeline(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [f.path for f in os.scandir('./modelsAug/') if f.is_dir()]\n",
    "\n",
    "ALL_MODELS = len(subfolders) * NUM_MODELS\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "for _ in range(ALL_MODELS):\n",
    "    model = createModel(1, 90)\n",
    "    models.append(model)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def load_weights(path):\n",
    "    global counter, models\n",
    "\n",
    "    for i in range(NUM_MODELS):\n",
    "        models[counter].load_weights(path + f'/model{i}/cp.ckpt')\n",
    "        counter += 1\n",
    "\n",
    "for sf in subfolders:\n",
    "    load_weights(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = createDataset('./val_data/Original')\n",
    "valset_length = tf.data.experimental.cardinality(valset).numpy()\n",
    "valset = valset.batch(batch_size = BATCH_SIZE)\n",
    "\n",
    "EVALUATE = False\n",
    "\n",
    "def evaluateModels():\n",
    "    global file\n",
    "\n",
    "    bestError = 9999\n",
    "    bestIndex = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for sf in subfolders:\n",
    "        error_avg = 0\n",
    "\n",
    "        for _ in range(NUM_MODELS):\n",
    "            error = models[counter].evaluate(valset, steps = valset_length / BATCH_SIZE, verbose = 0)\n",
    "            error_avg += error\n",
    "\n",
    "            if error < bestError:\n",
    "                bestError = error\n",
    "                bestIndex = counter\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        file.write(re.sub(r'./modelsAug/', r'', sf) + f' - error: {error_avg / NUM_MODELS}\\n\\n')\n",
    "\n",
    "    return bestIndex\n",
    "    \n",
    "\n",
    "if EVALUATE:\n",
    "    file = open('./evaluate.txt', 'w+')\n",
    "    bestIndex = evaluateModels()\n",
    "    file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDS = False\n",
    "\n",
    "def getLabelsAndPredictions():\n",
    "    global models\n",
    "\n",
    "    preds = [[] for _ in range(ALL_MODELS)]\n",
    "    labels = []\n",
    "\n",
    "    for images, labs in valset.take(-1):\n",
    "        labels.extend(labs.numpy())\n",
    "\n",
    "        for i in range(ALL_MODELS):\n",
    "            preds[i].extend(np.round(models[i].predict(images)))\n",
    "    \n",
    "    return labels, preds\n",
    "\n",
    "if PREDS:\n",
    "    labels, preds = getLabelsAndPredictions()\n",
    "    print(np.array(labels).shape, np.array(preds).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(real, predicted, threshold):\n",
    "    return abs(real - predicted) < threshold\n",
    "\n",
    "newModels = []\n",
    "\n",
    "def filterModels():\n",
    "    global models, labels, preds, newModels, bestIndex\n",
    "\n",
    "    for i in range(ALL_MODELS):\n",
    "        goodModel = False\n",
    "        c = 0\n",
    "\n",
    "        if i != bestIndex:\n",
    "            for k in range(valset_length):\n",
    "                if error(labels[k], preds[i][k], abs(labels[k] - preds[bestIndex][k])):\n",
    "                    c += 1\n",
    "                    \n",
    "                if c == 8:\n",
    "                    goodModel = True\n",
    "                    break\n",
    "        \n",
    "        if goodModel:\n",
    "            newModels.append(models[i])\n",
    "\n",
    "filterModels()\n",
    "newModels.append(models[bestIndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = tf.keras.Input(shape = (90, 90, 1))\n",
    "\n",
    "model_outputs = [model(model_input) for model in newModels]\n",
    "ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
    "\n",
    "ensemble_model = tf.keras.Model(inputs = model_input, outputs = ensemble_output)\n",
    "ensemble_model.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'mae')\n",
    "\n",
    "print(ensemble_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = createDataset('./train_data/Original')\n",
    "dataset_length = tf.data.experimental.cardinality(dataset).numpy()\n",
    "dataset, dataset_length = prepareDataset(dataset, dataset_length)\n",
    "\n",
    "valset = createDataset('./val_data/Original')\n",
    "valset_length = tf.data.experimental.cardinality(valset).numpy()\n",
    "valset, _ = prepareDataset(valset, valset_length)\n",
    "\n",
    "TRAIN_ENSEMBLE = False\n",
    "\n",
    "if TRAIN_ENSEMBLE:\n",
    "    history = ensemble_model.fit(dataset, epochs = 500, steps_per_epoch = dataset_length / BATCH_SIZE,  \n",
    "                                validation_data = valset, validation_steps = valset_length / BATCH_SIZE,\n",
    "                                callbacks = prepare_callbacks('./ensemble_modelAug/cp.ckpt'))\n",
    "\n",
    "    show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT = False\n",
    "\n",
    "def get_data_from_mat(train_file, test_file):\n",
    "    train_mat = scipy.io.loadmat(train_file) \n",
    "    test_mat = scipy.io.loadmat(test_file) \n",
    "\n",
    "    train_np = np.array(train_mat['train_data']).transpose(2, 0, 1)\n",
    "    test_np = np.array(test_mat['test_data']).transpose(2, 0, 1)\n",
    "\n",
    "    print(train_np.shape)\n",
    "    print(test_np.shape)\n",
    "\n",
    "    return train_np, test_np\n",
    "\n",
    "_, test_data = get_data_from_mat('./bap-imgap-212022/train_data.mat', './bap-imgap-212022/test_data.mat')\n",
    "\n",
    "\n",
    "if PREDICT:\n",
    "    predictions = ensemble_model.predict(test_data)\n",
    "    predictions = np.around(predictions, 0)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = False\n",
    "\n",
    "if WRITE:\n",
    "    f = open('submission.csv', 'w+')\n",
    "\n",
    "    f.write('id,age\\n')\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        f.write(str(i + 1) + ',' + str(int(predictions[i][0])) + '\\n')\n",
    "\n",
    "    f.flush()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16a84799b4554b55119e03db3af09132791ba03da067a3440fe10ca44b449a97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
